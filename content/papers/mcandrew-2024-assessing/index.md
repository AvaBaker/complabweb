---
title: "Assessing Human Judgment Forecasts in the Rapid Spread of the Mpox Outbreak: Insights and Challenges for Pandemic Preparedness"
date: 2024-03-19
tags: ["human judgment", "mpox"]
author: [Thomas McAndrew, Maimuna S. Majumder, Andrew A. Lover, Srini Venkatramanan, Paolo Bocchini, Tamay Besiroglu, Allison Codi, Gaia Dempsey, Sam Abbott, Sylvain Chevalier, Nikos I. Bosse, Juan Cambeiro, David Braun]
description: "We collected -- between May 19, 2022 and July 31, 2022 -- 1275 forecasts from 442 individuals of six questions about the mpox outbreak where ground truth data are now available. Individual human judgment forecasts and an equally weighted ensemble were evaluated, as well as compared to a random walk, autoregressive, and doubling time model."
summary: "We collected -- between May 19, 2022 and July 31, 2022 -- 1275 forecasts from 442 individuals of six questions about the mpox outbreak where ground truth data are now available. Individual human judgment forecasts and an equally weighted ensemble were evaluated, as well as compared to a random walk, autoregressive, and doubling time model."
cover:
    image: "featured.jpg"
    relative: false
editPost:
    URL: ""
    Text: ""
---

---

##### Download

+ [Paper](https://arxiv.org/abs/2404.14686)

---

##### Abstract
In May 2022, mpox (formerly monkeypox) spread to non-endemic countries rapidly. Human judgment is a forecasting approach that has been sparsely evaluated during the beginning of an outbreak. We collected -- between May 19, 2022 and July 31, 2022 -- 1275 forecasts from 442 individuals of six questions about the mpox outbreak where ground truth data are now available. Individual human judgment forecasts and an equally weighted ensemble were evaluated, as well as compared to a random walk, autoregressive, and doubling time model. We found (1) individual human judgment forecasts underestimated outbreak size, (2) the ensemble forecast median moved closer to the ground truth over time but uncertainty around the median did not appreciably decrease, and (3) compared to computational models, for 2-8 week ahead forecasts, the human judgment ensemble outperformed all three models when using median absolute error and weighted interval score; for one week ahead forecasts a random walk outperformed human judgment. We propose two possible explanations: at the time a forecast was submitted, the mode was correlated with the most recent (and smaller) observation that would eventually determine ground truth. Several forecasts were solicited on a logarithmic scale which may have caused humans to generate forecasts with unintended, large uncertainty intervals. To aide in outbreak preparedness, platforms that solicit human judgment forecasts may wish to assess whether specifying a forecast on logarithmic scale matches an individual's intended forecast, support human judgment by finding cues that are typically used to build forecasts, and, to improve performance, tailor their platform to allow forecasters to assign zero probability to events.

---


##### Citation

McAndrew, Thomas, et al. "Assessing Human Judgment Forecasts in the Rapid Spread of the Mpox Outbreak: Insights and Challenges for Pandemic Preparedness." arXiv preprint arXiv:2404.14686 (2024).

```
BibTeX
@article{mcandrew2024assessing,
  title={Assessing Human Judgment Forecasts in the Rapid Spread of the Mpox Outbreak: Insights and Challenges for Pandemic Preparedness},
  author={McAndrew, Thomas and Majumder, Maimuna S and Lover, Andrew A and Venkatramanan, Srini and Bocchini, Paolo and Besiroglu, Tamay and Codi, Allison and Dempsey, Gaia and Abbott, Sam and Chevalier, Sylvain and others},
  journal={arXiv preprint arXiv:2404.14686},
  year={2024}
}
```
---
